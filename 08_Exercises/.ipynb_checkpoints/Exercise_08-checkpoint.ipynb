{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTEBOOK 08\n",
    "\n",
    "In this notebook we will see how to use Monte Carlo methods in quantum mechanics.\n",
    "First, we will implement a Variational Monte Carlo algorithm (VMC) and then a Path Integral Monte Carlo one (PIMC), both for a particle in one dimension under the action of a potential $$V(x)=x^4 +\\frac{5}{2}x^{2} $$ not analytically soluble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE 08.1\n",
    "\n",
    "In this part of the notebook we will show how our code is able to calculate the expectation value of the Hamiltonian over a trial wave function $$\n",
    "\\Psi_T^{\\sigma,\\mu}(x) \\propto e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}+\n",
    "                               e^{-\\frac{(x+\\mu)^2}{2\\sigma^2}}\n",
    "$$\n",
    "with $\\mu=1$ and $\\sigma=0.5$ using the blocking technique.\n",
    "\n",
    "Conventions:\n",
    "\n",
    "$\\hbar=1$, $m=1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE 08.2\n",
    "\n",
    "Then comes the \"variational\" part of the VMC.\n",
    "\n",
    "- Our first idea was to design a \"Gradient Descent\" algorithm. This means that if we want to minimize a function $f(x)$ over the parameters $x_{i}$, at each step $t$ we have:\n",
    "\n",
    "$$\n",
    "x_{i}(t+1)=x_{i}(t)-\\eta*\\frac{\\partial f}{\\partial x_{i}}\n",
    "$$\n",
    "\n",
    "where $\\eta$ is the learning rate.\n",
    "The problem is how to calculate the derivative. Then hint comes from quantum computing, where you don't have access to analytical form of the function, but only its numerical values from measurement. Therefore a \"derivative\" that is an incremental ratio is calculated\n",
    "$$\n",
    "\\frac{\\partial f}{\\partial x_{i}} \\sim \\frac{f(x_{i}+h,x_{k})-f(x_{i},x_{k})}{h}\n",
    "$$\n",
    "\n",
    "when h is sufficiently small.\n",
    "\n",
    "This \"sufficiently small\" has a lower bound; the statistical uncertainty we have in calculating f as a Monte Marlo integral. This is not a problem since the error on the integral calulation is sufficiently small to let us choose $h=0.1$.\n",
    "\n",
    "Unfortunately, due to the nature of the function to minimize, namely $E_{loc}(\\sigma,\\mu)$, this algorithm is not guaranteed to converge. Moreover, it turn out to be very unstable, also when annealing factor are applied to the learning rate.\n",
    "\n",
    "\n",
    "- The second idea is therefore to proceed with simulated annealing.\n",
    "\n",
    "The algorithm works like this:\n",
    "\n",
    "1) calculate $E_{loc}(\\sigma,\\mu)$\n",
    "\n",
    "2) randomly generate two new parameters $\\sigma_{new}$ and $\\mu_{new}$\n",
    "\n",
    "3) if $E_{loc}(\\sigma_{new},\\mu_{new}) < E_{loc}(\\sigma,\\mu)$, the new parameters are the best found until now, so accept the move, otherwise, if the new energy is greater than before,a ccept the move only with a probability $e^{-\\frac{t}{\\tau}}$, where $t$ is the number of steps and $\\tau$ is a fine-tuned temperature for the system\n",
    "\n",
    "4) repeat step 2 and 3 until the parameters do not change anymore\n",
    "\n",
    "Also this method is not guaranteed to converge, but it proved to be very stable.\n",
    "\n",
    "Results are:\n",
    "\n",
    "$\\mu = 0.774863$\n",
    "\n",
    "$\\sigma = 0.631326$\n",
    "\n",
    "Those values gave an approximate ground state energy $E_{GS}=-0.459931$\n",
    "\n",
    "Now we can use those new parameters to calculate the ground state energy with metropolis algorithm and the blocking technique.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
